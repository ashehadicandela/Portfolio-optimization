
!pip install praw
!pip install nltk
!pip install emoji.py
!pip install en_core_web_sm

import praw
import pandas as pd
import en_core_web_sm
import emoji
import seaborn as sns
import matplotlib.pyplot as plt 
import spacy
import regex

import nltk
from nltk.tokenize import RegexpTokenizer
from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer
from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA
nltk.downloader.download('vader_lexicon')
from nltk import FreqDist

nltk.download('wordnet')
nltk.download('omw-1.4')

my_client_id = 'INSERT ID'
my_client_secret = 'INSERT CLIETN SECRET'
my_user_agent = 'CHOOSE A NAME'

reddit = praw.Reddit(client_id = my_client_id, client_secret = my_client_secret, user_agent = my_user_agent)

##################################################################################################################
# get hot posts from the any subreddit
##################################################################################################################

sub_reddit = 'TSLA'
hot_posts = 10

posts = []
ml_subreddit = reddit.subreddit(sub_reddit)
for post in ml_subreddit.hot(limit=hot_posts):
    posts.append([post.title, post.score, post.url, post.num_comments, post.selftext, post.created])
posts = pd.DataFrame(posts,columns=['title', 'score', 'url', 'num_comments', 'body', 'created'])
#posts

##################################################################################################################
#Text processing
##################################################################################################################

body_texts = []
for text in ml_subreddit.hot(limit=hot_posts):
    body_texts.append(posts.body)

title_texts = []
for text in ml_subreddit.hot(limit=hot_posts):
    title_texts.append(posts.title)

overall_text = body_texts + title_texts

list_1 = overall_text
list_1 = [str(i) for i in list_1]
string_uncleaned = ','.join(list_1)

try: 
  string_emojiless = emoji.get_emoji_regexp().sub(u'', string_uncleaned)
except:
  string_emojiless = string_uncleaned

tokenizer = RegexpTokenizer('\w+|\$[\d\.]+|http\S+')
tokenized_string = tokenizer.tokenize(string_emojiless)
lower_string_tokenized = [word.lower() for word in tokenized_string]

nlp = en_core_web_sm.load()
all_stopwords = nlp.Defaults.stop_words

text = lower_string_tokenized
tokens_without_sw = [word for word in text if not word in all_stopwords]

lemmatizer = WordNetLemmatizer()
lemmatized_tokens = ([lemmatizer.lemmatize(s) for s in tokens_without_sw])

stemmer = PorterStemmer()
stem_tokens = ([stemmer.stem(s) for s in tokens_without_sw])

cleaned_output = lemmatized_tokens 
#cleaned_output

##################################################################################################################
#Sentiment analysis
##################################################################################################################

sia = SIA()
results = []

for sentences in cleaned_output:
  pol_score = sia.polarity_scores(sentences)
  pol_score['words'] = sentences
  results.append(pol_score)

##################################################################################################################
#Research piece of code including neutral words
##################################################################################################################

pd.set_option('display.max_columns', None, 'max_colwidth', None)
df = pd.DataFrame.from_records(results)
df['label'] = 0
df.loc[df['compound']>0.1, 'label'] = 1
df.loc[df['compound']<-0.1, 'label'] = -1

fig, ax = plt.subplots(figsize = (8,8))
counts = df.label.value_counts(normalize = True)*100
sns.barplot(x=counts.index, y=counts, ax=ax)

ax.set_xticklabels(['Negative', 'Neutral', 'Positive'])
ax.set_ylabel('Percentage')

plt.show()

##################################################################################################################
#Remove neutral words
##################################################################################################################

df_positive_negative = df.loc[df['label'] !=0]

fig, ax = plt.subplots(figsize = (8,8))
counts = df_positive_negative.label.value_counts(normalize = True)*100
sns.barplot(x=counts.index, y=counts, ax=ax)

plt.title("Reddit sentiment of ticker '"+sub_reddit+"'")
ax.set_xticklabels(['Negative', 'Positive'])
ax.set_ylabel('Percentage')

plt.show()
